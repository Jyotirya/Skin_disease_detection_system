{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddacdf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c372288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18# type: ignore\n",
    "import medmnist\n",
    "from medmnist import DermaMNIST\n",
    "from medmnist import INFO, Evaluator\n",
    "from matplotlib import transforms\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as data\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "051fd31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants \n",
    "data_flag = 'dermamnist'\n",
    "download = False\n",
    "\n",
    "NUM_EPOCHS = 12\n",
    "BATCH_SIZE = 128\n",
    "lr = 0.001\n",
    "\n",
    "info = INFO[data_flag]\n",
    "task = info['task']\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])\n",
    "\n",
    "DataClass = getattr(medmnist, info['python_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "241ec82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x.convert('RGB') if x.mode == 'L' else x),\n",
    "    # Small zoom + crop around original size\n",
    "    transforms.RandomResizedCrop(size=28, scale=(0.9, 1.1)),  # small zoom in/out\n",
    "    transforms.RandomRotation(degrees=10, fill=0),            # random rotation\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),     # random brightness/contrast\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x.convert('RGB') if x.mode == 'L' else x),\n",
    "    transforms.CenterCrop(28),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "test_transform = val_transform\n",
    "\n",
    "pil_dataset = DermaMNIST(split='train', download=download)\n",
    "train_dataset = DermaMNIST(split='train', transform=train_transform, download=False)\n",
    "train_dataset_at_eval = DermaMNIST(split='train', transform=val_transform, download=False)\n",
    "val_dataset   = DermaMNIST(split='val',   transform=val_transform, download=False)\n",
    "test_dataset  = DermaMNIST(split='test',  transform=test_transform, download=False)\n",
    "\n",
    "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True) # type: ignore\n",
    "train_loader_at_eval = data.DataLoader(dataset=train_dataset_at_eval, batch_size=2*BATCH_SIZE, shuffle=False) # type: ignore\n",
    "val_loader = data.DataLoader(dataset=val_dataset, batch_size=2*BATCH_SIZE,   shuffle = False) # type: ignore\n",
    "test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75b25d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = Counter()\n",
    "for _, label in train_dataset:\n",
    "    label_counts[label.item()] += 1\n",
    "\n",
    "num_classes = len(label_counts)\n",
    "counts = np.array([label_counts[c] for c in range(num_classes)], dtype=np.float32)\n",
    "\n",
    "class_weights = 1.0 / (counts + 1e-6)\n",
    "class_weights = class_weights / class_weights.sum() * num_classes\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e903f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = resnet18(weights='IMAGENET1K_V1')\n",
    "\n",
    "# Freeze the backbone\n",
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in pretrained_model.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in pretrained_model.layer3.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Replace fc head (ResNet uses .fc, not .classifier)\n",
    "pretrained_model.fc = nn.Linear(pretrained_model.fc.in_features, n_classes)\n",
    "\n",
    "# Unfreeze the new head\n",
    "for param in pretrained_model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model = pretrained_model\n",
    "\n",
    "# Loss and optimizer\n",
    "if task == \"multi-label, binary-class\":\n",
    "    criterion = nn.BCEWithLogitsLoss(weight=class_weights)\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca3e7d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:30<00:00,  1.79it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/12], Loss: 1.7642, Val Loss: 1.7513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:31<00:00,  1.73it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/12], Loss: 1.4522, Val Loss: 1.3216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:31<00:00,  1.75it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/12], Loss: 1.3326, Val Loss: 1.4204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:32<00:00,  1.69it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/12], Loss: 1.2426, Val Loss: 1.2969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:32<00:00,  1.69it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/12], Loss: 1.1536, Val Loss: 1.2632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:31<00:00,  1.73it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/12], Loss: 1.1215, Val Loss: 1.2660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:32<00:00,  1.67it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/12], Loss: 1.0839, Val Loss: 1.2076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:32<00:00,  1.69it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/12], Loss: 1.0208, Val Loss: 1.2603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:31<00:00,  1.73it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/12], Loss: 1.0094, Val Loss: 1.2176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:32<00:00,  1.70it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/12], Loss: 1.0074, Val Loss: 1.2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:33<00:00,  1.66it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/12], Loss: 0.9638, Val Loss: 1.1879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:33<00:00,  1.65it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/12], Loss: 0.9453, Val Loss: 1.1354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop      \n",
    "store_train = []\n",
    "store_val = []\n",
    "\n",
    "patience = 3\n",
    "best_val = float('inf')\n",
    "patience_ctr = 0\n",
    "best_path = \"best_resnet18.pth\"\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    running_train_loss = 0.0\n",
    "    running_train_count = 0\n",
    "    running_val_loss = 0.0\n",
    "    running_val_count = 0\n",
    "    \n",
    "    model.train()\n",
    "    for inputs, targets in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        if task == 'multi-label, binary-class':\n",
    "            targets = targets.to(torch.float32)\n",
    "            loss = criterion(outputs, targets)\n",
    "        else:\n",
    "            targets = targets.squeeze().long()\n",
    "            loss = criterion(outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        bs = inputs.size(0)\n",
    "        running_train_loss += loss.item() * bs\n",
    "        running_train_count += bs\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(val_loader):\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            if task == 'multi-label, binary-class':\n",
    "                targets = targets.to(torch.float32)\n",
    "                loss_val = criterion(outputs, targets)\n",
    "            else:\n",
    "                targets = targets.squeeze().long()\n",
    "                loss_val = criterion(outputs, targets)\n",
    "            bs = inputs.size(0)\n",
    "            running_val_loss += loss_val.item() * bs\n",
    "            running_val_count += bs\n",
    "\n",
    "    epoch_train_loss = running_train_loss / running_train_count\n",
    "    epoch_val_loss = running_val_loss / running_val_count\n",
    "\n",
    "    scheduler.step(epoch_val_loss)\n",
    "\n",
    "    store_train.append(epoch_train_loss)\n",
    "    store_val.append(epoch_val_loss)\n",
    "\n",
    "    if epoch_val_loss < best_val:\n",
    "        best_val = epoch_val_loss\n",
    "        patience_ctr = 0\n",
    "        torch.save(model.state_dict(), best_path)  # keep best model\n",
    "    else:\n",
    "        patience_ctr += 1\n",
    "        if patience_ctr >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}, Val Loss: {:.4f}'\n",
    "          .format(epoch+1, NUM_EPOCHS, epoch_train_loss, epoch_val_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bc883d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Evaluating ...\n",
      "train  auc: 0.916  acc:0.594\n",
      "test  auc: 0.865  acc:0.549\n"
     ]
    }
   ],
   "source": [
    "def test(split):\n",
    "    model.eval()\n",
    "    y_true = torch.tensor([])\n",
    "    y_score = torch.tensor([])\n",
    "    \n",
    "    data_loader = test_loader if split == 'test' else train_loader_at_eval\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            if task == 'multi-label, binary-class':\n",
    "                targets = targets.to(torch.float32)\n",
    "                outputs = outputs.softmax(dim=-1)\n",
    "            else:\n",
    "                targets = targets.squeeze().long()\n",
    "                outputs = outputs.softmax(dim=-1)\n",
    "                targets = targets.float().resize_(len(targets), 1)\n",
    "\n",
    "            y_true = torch.cat((y_true, targets), 0)\n",
    "            y_score = torch.cat((y_score, outputs), 0)\n",
    "\n",
    "        y_true = y_true.numpy()\n",
    "        y_score = y_score.detach().numpy()\n",
    "        \n",
    "        evaluator = Evaluator(data_flag, split)\n",
    "        metrics = evaluator.evaluate(y_score)\n",
    "    \n",
    "        print('%s  auc: %.3f  acc:%.3f' % (split, *metrics))\n",
    "\n",
    "print('==> Evaluating ...')\n",
    "test('train')\n",
    "test('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9ec50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fine Tuning                      \n",
    "#learning rate scheduling - Helps to improve accuracy            \n",
    "#increase epoch - I don't have GPU sad\n",
    "#decrease batch size - same\n",
    "#use better backbone - same\n",
    "#data transforms - Done\n",
    "#better optimizer - Need to try with diffrent SGD vs AdamW\n",
    "#early stopping - Extermly useful we don't know the right number of epoch we should run on \n",
    "# Apply class weights - Used for class Imbalance which is the case in our dataset\n",
    "# better comparisons\n",
    "# more layers to be frozen - Freezing one block is enough"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Global Env",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
