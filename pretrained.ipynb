{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ddacdf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from tensorflow) (6.33.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from tensorflow) (3.12.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from tensorflow) (2.2.6)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: pillow in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.4)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/jyotirya-agrawal/Desktop/DS203/Assignment 8/venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c372288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18# type: ignore\n",
    "import medmnist\n",
    "from medmnist import DermaMNIST\n",
    "from medmnist import INFO, Evaluator\n",
    "from matplotlib import transforms\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as data\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "051fd31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # transforms.RandomRotation(degrees=10, fill=0),            # random rotation\n",
    "    # transforms.ColorJitter(brightness=0.2, contrast=0.2),     # random brightness/contrast# Constants \n",
    "data_flag = 'dermamnist'\n",
    "download = False\n",
    "\n",
    "NUM_EPOCHS = 15\n",
    "BATCH_SIZE = 64\n",
    "lr = 0.001\n",
    "\n",
    "info = INFO[data_flag]\n",
    "task = info['task']\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])\n",
    "\n",
    "DataClass = getattr(medmnist, info['python_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "241ec82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x.convert('RGB') if x.mode == 'L' else x),\n",
    "    # Small zoom + crop around original size\n",
    "    # transforms.RandomResizedCrop(size=28, scale=(0.9, 1.1)),  # small zoom in/out\n",
    "    transforms.RandomRotation(degrees=10, fill=0),            # random rotation\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),     # random brightness/contrast\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x.convert('RGB') if x.mode == 'L' else x),\n",
    "    transforms.CenterCrop(28),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "test_transform = val_transform\n",
    "\n",
    "pil_dataset = DermaMNIST(split='train', download=download)\n",
    "train_dataset = DermaMNIST(split='train', transform=train_transform, download=False)\n",
    "train_dataset_at_eval = DermaMNIST(split='train', transform=val_transform, download=False)\n",
    "val_dataset   = DermaMNIST(split='val',   transform=val_transform, download=False)\n",
    "test_dataset  = DermaMNIST(split='test',  transform=test_transform, download=False)\n",
    "\n",
    "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True) # type: ignore\n",
    "train_loader_at_eval = data.DataLoader(dataset=train_dataset_at_eval, batch_size=2*BATCH_SIZE, shuffle=False) # type: ignore\n",
    "val_loader = data.DataLoader(dataset=val_dataset, batch_size=2*BATCH_SIZE,   shuffle = False) # type: ignore\n",
    "test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75b25d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = Counter()\n",
    "for _, label in train_dataset:\n",
    "    label_counts[label.item()] += 1\n",
    "\n",
    "num_classes = len(label_counts)\n",
    "counts = np.array([label_counts[c] for c in range(num_classes)], dtype=np.float32)\n",
    "\n",
    "class_weights = 1.0 / (counts + 1e-6)\n",
    "class_weights = class_weights / class_weights.sum() * num_classes\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e903f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = resnet18(weights='IMAGENET1K_V1')\n",
    "\n",
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "\n",
    "# Replace fc head (ResNet uses .fc, not .classifier)\n",
    "pretrained_model.fc = nn.Linear(pretrained_model.fc.in_features, n_classes)\n",
    "\n",
    "# Unfreeze the new head\n",
    "for param in pretrained_model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model = pretrained_model\n",
    "\n",
    "# Loss and optimizer\n",
    "if task == \"multi-label, binary-class\":\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca3e7d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:45<00:00,  2.42it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 0.9957, Val Loss: 0.8101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:46<00:00,  2.38it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00,  9.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/15], Loss: 0.7996, Val Loss: 0.7465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:44<00:00,  2.48it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/15], Loss: 0.7425, Val Loss: 0.7380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:46<00:00,  2.38it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 10.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/15], Loss: 0.7193, Val Loss: 0.7089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:45<00:00,  2.42it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/15], Loss: 0.6808, Val Loss: 0.6801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:46<00:00,  2.37it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/15], Loss: 0.6488, Val Loss: 0.6940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:46<00:00,  2.38it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 13.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/15], Loss: 0.6374, Val Loss: 0.6752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:46<00:00,  2.38it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 11.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/15], Loss: 0.6113, Val Loss: 0.6596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:45<00:00,  2.42it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00,  9.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/15], Loss: 0.5967, Val Loss: 0.6674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:46<00:00,  2.37it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 11.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/15], Loss: 0.5683, Val Loss: 0.6601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:47<00:00,  2.33it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00,  8.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/15], Loss: 0.5449, Val Loss: 0.6935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:47<00:00,  2.33it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/15], Loss: 0.5062, Val Loss: 0.6651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:44<00:00,  2.49it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 11.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop      \n",
    "store_train = []\n",
    "store_val = []\n",
    "\n",
    "patience = 5\n",
    "best_val = float('inf')\n",
    "patience_ctr = 0\n",
    "best_path = \"best_resnet18.pth\"\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    running_train_loss = 0.0\n",
    "    running_train_count = 0\n",
    "    running_val_loss = 0.0\n",
    "    running_val_count = 0\n",
    "    \n",
    "    model.train()\n",
    "    for inputs, targets in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        if task == 'multi-label, binary-class':\n",
    "            targets = targets.to(torch.float32)\n",
    "            loss = criterion(outputs, targets)\n",
    "        else:\n",
    "            targets = targets.squeeze().long()\n",
    "            loss = criterion(outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        bs = inputs.size(0)\n",
    "        running_train_loss += loss.item() * bs\n",
    "        running_train_count += bs\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(val_loader):\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            if task == 'multi-label, binary-class':\n",
    "                targets = targets.to(torch.float32)\n",
    "                loss_val = criterion(outputs, targets)\n",
    "            else:\n",
    "                targets = targets.squeeze().long()\n",
    "                loss_val = criterion(outputs, targets)\n",
    "            bs = inputs.size(0)\n",
    "            running_val_loss += loss_val.item() * bs\n",
    "            running_val_count += bs\n",
    "\n",
    "    epoch_train_loss = running_train_loss / running_train_count\n",
    "    epoch_val_loss = running_val_loss / running_val_count\n",
    "\n",
    "    scheduler.step(epoch_val_loss)\n",
    "\n",
    "    store_train.append(epoch_train_loss)\n",
    "    store_val.append(epoch_val_loss)\n",
    "\n",
    "    if epoch_val_loss < best_val:\n",
    "        best_val = epoch_val_loss\n",
    "        patience_ctr = 0\n",
    "    else:\n",
    "        patience_ctr += 1\n",
    "        if patience_ctr >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}, Val Loss: {:.4f}'\n",
    "          .format(epoch+1, NUM_EPOCHS, epoch_train_loss, epoch_val_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "79bc883d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Evaluating ...\n",
      "train  auc: 0.978  acc:0.865\n",
      "test  auc: 0.930  acc:0.775\n"
     ]
    }
   ],
   "source": [
    "def test(split):\n",
    "    model.eval()\n",
    "    y_true = torch.tensor([])\n",
    "    y_score = torch.tensor([])\n",
    "    \n",
    "    data_loader = test_loader if split == 'test' else train_loader_at_eval\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            if task == 'multi-label, binary-class':\n",
    "                targets = targets.to(torch.float32)\n",
    "                outputs = outputs.softmax(dim=-1)\n",
    "            else:\n",
    "                targets = targets.squeeze().long()\n",
    "                outputs = outputs.softmax(dim=-1)\n",
    "                targets = targets.float().resize_(len(targets), 1)\n",
    "\n",
    "            y_true = torch.cat((y_true, targets), 0)\n",
    "            y_score = torch.cat((y_score, outputs), 0)\n",
    "\n",
    "        y_true = y_true.numpy()\n",
    "        y_score = y_score.detach().numpy()\n",
    "        \n",
    "        evaluator = Evaluator(data_flag, split)\n",
    "        metrics = evaluator.evaluate(y_score)\n",
    "    \n",
    "        print('%s  auc: %.3f  acc:%.3f' % (split, *metrics))\n",
    "\n",
    "print('==> Evaluating ...')\n",
    "test('train')\n",
    "test('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb9ec50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fine Tuning                      \n",
    "#learning rate scheduling - Helps to improve accuracy            \n",
    "#increase epoch -\n",
    "#decrease batch size - \n",
    "#use better backbone -\n",
    "#data transforms - Done\n",
    "#better optimizer - Need to try with diffrent SGD vs AdamW\n",
    "#early stopping - Extermly useful we don't know the right number of epoch we should run on \n",
    "# Apply class weights - Used for class Imbalance which is the case in our dataset\n",
    "# better comparisons\n",
    "# more layers to be frozen - Freezing one block is enough"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Global Env",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
